<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>NLTK: Natural Language Made Easy &#8212; Stat 159/259 - Reproducible and Collaborative Data Science 1 documentation</title>
    
    <link rel="stylesheet" href="../../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../',
        VERSION:     '1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Data - an introduction to the world of Pandas" href="../12-data-intro.html" />
    <link rel="prev" title="Strings" href="11-strings.html" />
   
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head>
  <body role="document">
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput,
div.nbinput div.prompt,
div.nbinput div.input_area,
div.nbinput div[class*=highlight],
div.nbinput div[class*=highlight] pre,
div.nboutput,
div.nbinput div.prompt,
div.nbinput div.output_area,
div.nboutput div[class*=highlight],
div.nboutput div[class*=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput,
div.nboutput {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput,
    div.nboutput {
        flex-direction: column;
    }
}

/* input container */
div.nbinput {
    padding-top: 5px;
}

/* last container */
div.nblast {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput div.prompt pre {
    color: #303F9F;
}

/* output prompt */
div.nboutput div.prompt pre {
    color: #D84315;
}

/* all prompts */
div.nbinput div.prompt,
div.nboutput div.prompt {
    min-width: 8ex;
    padding-top: 0.4em;
    padding-right: 0.4em;
    text-align: right;
    flex: 0;
}
@media (max-width: 540px) {
    div.nbinput div.prompt,
    div.nboutput div.prompt {
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput div.prompt.empty {
        padding: 0;
    }
}

/* disable scrollbars on prompts */
div.nbinput div.prompt pre,
div.nboutput div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput div.input_area,
div.nboutput div.output_area {
    padding: 0.4em;
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput div.input_area,
    div.nboutput div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput div.input_area {
    border: 1px solid #cfcfcf;
    border-radius: 2px;
    background: #f7f7f7;
}

/* override MathJax center alignment in output cells */
div.nboutput div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.pngmath center alignment in output cells */
div.nboutput div.math p {
    text-align: left;
}

/* standard error */
div.nboutput div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-bold { font-weight: bold; }
</style>
<div class="section" id="NLTK:-Natural-Language-Made-Easy">
<h1>NLTK: Natural Language Made Easy<a class="headerlink" href="#NLTK:-Natural-Language-Made-Easy" title="Permalink to this headline">¶</a></h1>
<p>Dealing with text is hard! Thankfully, it&#8217;s hard for everyone, so tools
exist to make it easier.</p>
<p>NLTK, the Natural Language Toolkit, is a python package &#8220;for building
Python programs to work with human language data&#8221;. It has many tools for
basic language processing (e.g. tokenization, <span class="math">\(n\)</span>-grams, etc.) as
well as tools for more complicated language processing (e.g. part of
speech tagging, parse trees, etc.).</p>
<p>NLTK has an <a class="reference external" href="http://www.nltk.org/book/">associated book about NLP</a>
that provides some context for the corpora and models.</p>
<div class="section" id="Installing-NLTK,-or-&quot;why-do-I-need-to-download-so-much-data?&quot;">
<h2>Installing NLTK, or &#8220;why do I need to download so much data?&#8221;<a class="headerlink" href="#Installing-NLTK,-or-"why-do-I-need-to-download-so-much-data?"" title="Permalink to this headline">¶</a></h2>
<p>We can <code class="docutils literal"><span class="pre">conda</span> <span class="pre">install</span> <span class="pre">nltk</span></code> to get the package. Then we need to do
something somewhat strange: we have to download data.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">nltk</span>
<span class="c1">#nltk.download()</span>
</pre></div>
</div>
</div>
<p>This pops up a GUI where we can choose what data to download.</p>
<p>What is this stuff? The data is separated into two categories:</p>
<ol class="arabic simple">
<li>Corpora<ul>
<li>These data are a set of collections of text.</li>
</ul>
</li>
<li>Models<ul>
<li>These are data (e.g. weights, etc.) for trained models.</li>
</ul>
</li>
</ol>
<p>NLTK provides several collections of data to make installing easier.</p>
<ul class="simple">
<li><code class="docutils literal"><span class="pre">all</span></code>: All corpora and models</li>
<li><code class="docutils literal"><span class="pre">all-corpora</span></code>: All corpora, no models</li>
<li><code class="docutils literal"><span class="pre">all-nltk</span></code>: Everything plus more data from the website</li>
<li><code class="docutils literal"><span class="pre">book</span></code>: Data to run the associated book</li>
<li><code class="docutils literal"><span class="pre">popular</span></code>: The most popular packages</li>
<li><code class="docutils literal"><span class="pre">third-party</span></code>: Extra data from third parties</li>
</ul>
<p>Downloading the <code class="docutils literal"><span class="pre">popular</span></code> collection is recommended.</p>
</div>
<div class="section" id="Analyzing-tweets">
<h2>Analyzing tweets<a class="headerlink" href="#Analyzing-tweets" title="Permalink to this headline">¶</a></h2>
<div class="section" id="First-pass">
<h3>First pass<a class="headerlink" href="#First-pass" title="Permalink to this headline">¶</a></h3>
<p>Let&#8217;s take a look at one corpus in particular: positive and negative
tweets.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="c1"># read some twitter data</span>
<span class="n">neg_id</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">corpus</span><span class="o">.</span><span class="n">twitter_samples</span><span class="o">.</span><span class="n">fileids</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">neg_tweets</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">corpus</span><span class="o">.</span><span class="n">twitter_samples</span><span class="o">.</span><span class="n">strings</span><span class="p">(</span><span class="n">neg_id</span><span class="p">)</span>
<span class="n">pos_id</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">corpus</span><span class="o">.</span><span class="n">twitter_samples</span><span class="o">.</span><span class="n">fileids</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">pos_tweets</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">corpus</span><span class="o">.</span><span class="n">twitter_samples</span><span class="o">.</span><span class="n">strings</span><span class="p">(</span><span class="n">pos_id</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="nb">print</span><span class="p">(</span><span class="n">pos_tweets</span><span class="p">[</span><span class="mi">10</span><span class="p">])</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">neg_tweets</span><span class="p">[</span><span class="mi">10</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
#FollowFriday @wncer1 @Defense_gouv for being top influencers in my community this week :)

I have a really good m&amp;amp;g idea but I&#39;m never going to meet them :(((
</pre></div></div>
</div>
<p>How does the language in positive and negative tweets differ?</p>
<p>We can start by looking at how the words differ. NLTK provides tools for
tokenization.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">tokenize_tweets1</span><span class="p">(</span><span class="n">tweets</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Get all of the tokens in a set of tweets&quot;&quot;&quot;</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">token</span> <span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="n">tweets</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">nltk</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">tweet</span><span class="p">)]</span>
    <span class="k">return</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>What does this output?</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">pos_tokens</span> <span class="o">=</span> <span class="n">tokenize_tweets1</span><span class="p">(</span><span class="n">pos_tweets</span><span class="p">)</span>
<span class="n">neg_tokens</span> <span class="o">=</span> <span class="n">tokenize_tweets1</span><span class="p">(</span><span class="n">neg_tweets</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">pos_tokens</span><span class="p">[:</span><span class="mi">10</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[&#39;#&#39;, &#39;FollowFriday&#39;, &#39;@&#39;, &#39;France_Inte&#39;, &#39;@&#39;, &#39;PKuchly57&#39;, &#39;@&#39;, &#39;Milipol_Paris&#39;, &#39;for&#39;, &#39;being&#39;]
</pre></div></div>
</div>
<p>We can look at the most common words (like in the first homework) using
Python&#8217;s Counter class.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">collections</span> <span class="k">import</span> <span class="n">Counter</span>

<span class="n">pos_count</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="n">pos_tokens</span><span class="p">)</span>
<span class="n">neg_count</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="n">neg_tokens</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">pos_count</span><span class="o">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>Out[7]:
</pre></div>
</div>
<div class="output_area highlight-none"><div class="highlight"><pre>
<span></span>[(&#39;:&#39;, 6667),
 (&#39;)&#39;, 5165),
 (&#39;@&#39;, 5119),
 (&#39;!&#39;, 1920),
 (&#39;you&#39;, 1427),
 (&#39;.&#39;, 1323),
 (&#39;#&#39;, 1292),
 (&#39;I&#39;, 1176),
 (&#39;to&#39;, 1063),
 (&#39;the&#39;, 997),
 (&#39;,&#39;, 964),
 (&#39;a&#39;, 881),
 (&#39;-&#39;, 863),
 (&#39;http&#39;, 856),
 (&#39;for&#39;, 749),
 (&#39;D&#39;, 662),
 (&#39;and&#39;, 656),
 (&#39;?&#39;, 582),
 (&#39;it&#39;, 566),
 (&#39;my&#39;, 484)]
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">neg_count</span><span class="o">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>Out[8]:
</pre></div>
</div>
<div class="output_area highlight-none"><div class="highlight"><pre>
<span></span>[(&#39;(&#39;, 7076),
 (&#39;:&#39;, 5959),
 (&#39;@&#39;, 3181),
 (&#39;I&#39;, 1986),
 (&#39;.&#39;, 1078),
 (&#39;to&#39;, 1067),
 (&#39;#&#39;, 913),
 (&#39;!&#39;, 895),
 (&#39;the&#39;, 846),
 (&#39;,&#39;, 733),
 (&#39;you&#39;, 707),
 (&#39;i&#39;, 684),
 (&#39;?&#39;, 650),
 (&#39;my&#39;, 629),
 (&#39;a&#39;, 626),
 (&quot;n&#39;t&quot;, 614),
 (&#39;and&#39;, 613),
 (&#39;-&#39;, 600),
 (&#39;it&#39;, 591),
 (&#39;me&#39;, 520)]
</pre></div>
</div>
</div>
<p>The two most common tokens for postiive tweets are &#8221;:&#8221; and &#8221;)&#8221; and the
tweo most common tokens for negative tweets are &#8220;(&#8221; and &#8221;:&#8221;. These are
smiley and frowny faces! The basic word tokenizer is treating these as
separate tokens, which makes sense in most cases but not for text from
social media.</p>
</div>
<div class="section" id="A-better-tokenizer">
<h3>A better tokenizer<a class="headerlink" href="#A-better-tokenizer" title="Permalink to this headline">¶</a></h3>
<p>We&#8217;re not the first people to see this problem, and NLTK actually has a
wide set of tokenizers in the <code class="docutils literal"><span class="pre">`nltk.tokenizer</span></code>
module &lt;<a class="reference external" href="http://www.nltk.org/api/nltk.tokenize.html">http://www.nltk.org/api/nltk.tokenize.html</a>&gt;`__. In particular,
there&#8217;s a <a class="reference external" href="http://www.nltk.org/api/nltk.tokenize.html#module-nltk.tokenize.casual">tokenizer that&#8217;s optimized for
tweets</a>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">tokenize_tweets2</span><span class="p">(</span><span class="n">tweets</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Get all of the tokens in a set of tweets&quot;&quot;&quot;</span>
    <span class="n">twt</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">tokenize</span><span class="o">.</span><span class="n">TweetTokenizer</span><span class="p">(</span><span class="n">strip_handles</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduce_len</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">token</span> <span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="n">tweets</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">twt</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">tweet</span><span class="p">)]</span>
    <span class="k">return</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">pos_tokens</span> <span class="o">=</span> <span class="n">tokenize_tweets2</span><span class="p">(</span><span class="n">pos_tweets</span><span class="p">)</span>
<span class="n">neg_tokens</span> <span class="o">=</span> <span class="n">tokenize_tweets2</span><span class="p">(</span><span class="n">neg_tweets</span><span class="p">)</span>
<span class="n">pos_count</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="n">pos_tokens</span><span class="p">)</span>
<span class="n">neg_count</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="n">neg_tokens</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">pos_count</span><span class="o">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>Out[11]:
</pre></div>
</div>
<div class="output_area highlight-none"><div class="highlight"><pre>
<span></span>[(&#39;:)&#39;, 3691),
 (&#39;!&#39;, 1844),
 (&#39;you&#39;, 1341),
 (&#39;.&#39;, 1341),
 (&#39;to&#39;, 1065),
 (&#39;the&#39;, 999),
 (&#39;,&#39;, 964),
 (&#39;I&#39;, 890),
 (&#39;a&#39;, 888),
 (&#39;for&#39;, 749),
 (&#39;:-)&#39;, 701),
 (&#39;and&#39;, 660),
 (&#39;:D&#39;, 658),
 (&#39;?&#39;, 581),
 (&#39;)&#39;, 525),
 (&#39;my&#39;, 484),
 (&#39;in&#39;, 481),
 (&#39;it&#39;, 460),
 (&#39;is&#39;, 418),
 (&#39;of&#39;, 403)]
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">neg_count</span><span class="o">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>Out[12]:
</pre></div>
</div>
<div class="output_area highlight-none"><div class="highlight"><pre>
<span></span>[(&#39;:(&#39;, 4585),
 (&#39;I&#39;, 1587),
 (&#39;(&#39;, 1180),
 (&#39;.&#39;, 1092),
 (&#39;to&#39;, 1068),
 (&#39;the&#39;, 846),
 (&#39;!&#39;, 831),
 (&#39;,&#39;, 734),
 (&#39;you&#39;, 660),
 (&#39;?&#39;, 644),
 (&#39;my&#39;, 629),
 (&#39;a&#39;, 627),
 (&#39;i&#39;, 620),
 (&#39;and&#39;, 614),
 (&#39;me&#39;, 524),
 (&#39;:-(&#39;, 501),
 (&#39;so&#39;, 466),
 (&#39;is&#39;, 456),
 (&#39;it&#39;, 449),
 (&#39;in&#39;, 421)]
</pre></div>
</div>
</div>
<p>Much better! This tokenizer got rid of twitter handles for us, so no
more &#8220;&#64;&#8221; tokens, and catches emoticons. However, there are still some
questions:</p>
<ol class="arabic simple">
<li>Should we count a capitalized word differently from a non-capitalized
word? e.g. should &#8220;Thanks&#8221; be different from &#8220;thanks&#8221;?</li>
<li>Do we want to be counting punctuation?</li>
<li>Do we want to count words like &#8220;I&#8221;, &#8220;me&#8221;, etc.?</li>
</ol>
<p>Using a combination of NLTK and basic Python string tools we can address
these concerns.</p>
<p>We can easily take a string and get a lowercase version of it.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="s2">&quot;ThIS IS a cRaZy sTRing&quot;</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>Out[13]:
</pre></div>
</div>
<div class="output_area highlight-none"><div class="highlight"><pre>
<span></span>&#39;this is a crazy string&#39;
</pre></div>
</div>
</div>
<p>The <code class="docutils literal"><span class="pre">string</span></code> module in base Python has a set of punctuation for the
latin alphabet.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">string</span>

<span class="n">string</span><span class="o">.</span><span class="n">punctuation</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>Out[14]:
</pre></div>
</div>
<div class="output_area highlight-none"><div class="highlight"><pre>
<span></span>&#39;!&quot;#$%&amp;\&#39;()*+,-./:;&lt;=&gt;?@[\\]^_`{|}~&#39;
</pre></div>
</div>
</div>
<p>NLTK has a collection of &#8220;stop words&#8221; for many languages, including
English. This is one of the corpora we downloaded.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="k">import</span> <span class="n">stopwords</span>

<span class="n">stopwords</span><span class="o">.</span><span class="n">words</span><span class="p">(</span><span class="s2">&quot;english&quot;</span><span class="p">)[:</span><span class="mi">20</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>Out[15]:
</pre></div>
</div>
<div class="output_area highlight-none"><div class="highlight"><pre>
<span></span>[&#39;i&#39;,
 &#39;me&#39;,
 &#39;my&#39;,
 &#39;myself&#39;,
 &#39;we&#39;,
 &#39;our&#39;,
 &#39;ours&#39;,
 &#39;ourselves&#39;,
 &#39;you&#39;,
 &#39;your&#39;,
 &#39;yours&#39;,
 &#39;yourself&#39;,
 &#39;yourselves&#39;,
 &#39;he&#39;,
 &#39;him&#39;,
 &#39;his&#39;,
 &#39;himself&#39;,
 &#39;she&#39;,
 &#39;her&#39;,
 &#39;hers&#39;]
</pre></div>
</div>
</div>
<p>We can combine all of these into our tokenizer</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">tokenize_tweets3</span><span class="p">(</span><span class="n">tweets</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Get all of the tokens in a set of tweets&quot;&quot;&quot;</span>
    <span class="n">twt</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">tokenize</span><span class="o">.</span><span class="n">TweetTokenizer</span><span class="p">(</span><span class="n">strip_handles</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduce_len</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="c1"># combine stop words and punctuation</span>
    <span class="n">stop</span> <span class="o">=</span> <span class="n">stopwords</span><span class="o">.</span><span class="n">words</span><span class="p">(</span><span class="s2">&quot;english&quot;</span><span class="p">)</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">string</span><span class="o">.</span><span class="n">punctuation</span><span class="p">)</span>
    <span class="c1"># filter out stop words and punctuation and send to lower case</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">token</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="n">tweets</span>
              <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">twt</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">tweet</span><span class="p">)</span>
              <span class="k">if</span> <span class="n">token</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stop</span><span class="p">]</span>
    <span class="k">return</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">pos_tokens</span> <span class="o">=</span> <span class="n">tokenize_tweets3</span><span class="p">(</span><span class="n">pos_tweets</span><span class="p">)</span>
<span class="n">neg_tokens</span> <span class="o">=</span> <span class="n">tokenize_tweets3</span><span class="p">(</span><span class="n">neg_tweets</span><span class="p">)</span>
<span class="n">pos_count</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="n">pos_tokens</span><span class="p">)</span>
<span class="n">neg_count</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="n">neg_tokens</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">pos_count</span><span class="o">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>Out[18]:
</pre></div>
</div>
<div class="output_area highlight-none"><div class="highlight"><pre>
<span></span>[(&#39;:)&#39;, 3691),
 (&#39;:-)&#39;, 701),
 (&#39;:d&#39;, 658),
 (&#39;thanks&#39;, 392),
 (&#39;follow&#39;, 304),
 (&#39;...&#39;, 290),
 (&#39;love&#39;, 273),
 (&#39;thank&#39;, 247),
 (&#39;u&#39;, 245),
 (&#39;good&#39;, 234),
 (&#39;like&#39;, 218),
 (&#39;day&#39;, 209),
 (&#39;happy&#39;, 191),
 (&quot;i&#39;m&quot;, 183),
 (&#39;hi&#39;, 173),
 (&#39;great&#39;, 172),
 (&#39;get&#39;, 168),
 (&#39;see&#39;, 167),
 (&#39;back&#39;, 162),
 (&quot;it&#39;s&quot;, 162)]
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">neg_count</span><span class="o">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>Out[19]:
</pre></div>
</div>
<div class="output_area highlight-none"><div class="highlight"><pre>
<span></span>[(&#39;:(&#39;, 4585),
 (&#39;:-(&#39;, 501),
 (&quot;i&#39;m&quot;, 343),
 (&#39;...&#39;, 332),
 (&#39;please&#39;, 274),
 (&#39;miss&#39;, 238),
 (&#39;want&#39;, 218),
 (&#39;♛&#39;, 210),
 (&#39;》&#39;, 210),
 (&#39;like&#39;, 206),
 (&#39;u&#39;, 193),
 (&#39;get&#39;, 180),
 (&quot;can&#39;t&quot;, 180),
 (&quot;it&#39;s&quot;, 178),
 (&quot;don&#39;t&quot;, 176),
 (&#39;sorry&#39;, 149),
 (&#39;one&#39;, 144),
 (&#39;follow&#39;, 142),
 (&#39;time&#39;, 141),
 (&#39;much&#39;, 139)]
</pre></div>
</div>
</div>
</div>
<div class="section" id="Additional-processing">
<h3>Additional processing<a class="headerlink" href="#Additional-processing" title="Permalink to this headline">¶</a></h3>
<p>How we pre-process text is very important. NLTK provides more tools for
pre-processing.</p>
<p>One popular method of pre-processing is <strong>stemming</strong>. The idea here is
to find the &#8220;root&#8221; of each word.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">nltk.stem</span> <span class="k">import</span> <span class="n">PorterStemmer</span>

<span class="n">stemmer</span> <span class="o">=</span> <span class="n">PorterStemmer</span><span class="p">()</span>
<span class="n">stemmer</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="s2">&quot;actually&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>Out[20]:
</pre></div>
</div>
<div class="output_area highlight-none"><div class="highlight"><pre>
<span></span>&#39;actual&#39;
</pre></div>
</div>
</div>
<p>Does this always work how we want?</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="nb">print</span><span class="p">(</span><span class="n">stemmer</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="s2">&quot;please&quot;</span><span class="p">),</span> <span class="n">stemmer</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="s2">&quot;pleasing&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
pleas pleas
</pre></div></div>
</div>
<p>Let&#8217;s update the tokenizer</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [22]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">tokenize_tweets4</span><span class="p">(</span><span class="n">tweets</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Get all of the tokens in a set of tweets&quot;&quot;&quot;</span>
    <span class="n">twt</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">tokenize</span><span class="o">.</span><span class="n">TweetTokenizer</span><span class="p">(</span><span class="n">strip_handles</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduce_len</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="c1"># combine stop words and punctuation</span>
    <span class="n">stop</span> <span class="o">=</span> <span class="n">stopwords</span><span class="o">.</span><span class="n">words</span><span class="p">(</span><span class="s2">&quot;english&quot;</span><span class="p">)</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">string</span><span class="o">.</span><span class="n">punctuation</span><span class="p">)</span>
    <span class="c1"># create the stemmer</span>
    <span class="n">stemmer</span> <span class="o">=</span> <span class="n">PorterStemmer</span><span class="p">()</span>
    <span class="c1"># filter out stop words and punctuation and send to lower case</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span> <span class="n">stemmer</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="n">token</span><span class="p">)</span> <span class="k">for</span> <span class="n">tweet</span> <span class="ow">in</span> <span class="n">tweets</span>
              <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">twt</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">tweet</span><span class="p">)</span>
              <span class="k">if</span> <span class="n">token</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stop</span><span class="p">]</span>
    <span class="k">return</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
<span class="n">pos_tokens</span> <span class="o">=</span> <span class="n">tokenize_tweets4</span><span class="p">(</span><span class="n">pos_tweets</span><span class="p">)</span>
<span class="n">neg_tokens</span> <span class="o">=</span> <span class="n">tokenize_tweets4</span><span class="p">(</span><span class="n">neg_tweets</span><span class="p">)</span>
<span class="n">pos_count</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="n">pos_tokens</span><span class="p">)</span>
<span class="n">neg_count</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="n">neg_tokens</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">pos_count</span><span class="o">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>Out[23]:
</pre></div>
</div>
<div class="output_area highlight-none"><div class="highlight"><pre>
<span></span>[(&#39;:)&#39;, 3691),
 (&#39;:-)&#39;, 701),
 (&#39;:D&#39;, 658),
 (&#39;thank&#39;, 643),
 (&#39;follow&#39;, 443),
 (&#39;love&#39;, 398),
 (&#39;...&#39;, 290),
 (&#39;day&#39;, 245),
 (&#39;good&#39;, 238),
 (&#39;like&#39;, 232),
 (&#39;u&#39;, 228),
 (&#39;get&#39;, 209),
 (&#39;happi&#39;, 206),
 (&#39;see&#39;, 186),
 (&quot;i&#39;m&quot;, 183),
 (&#39;great&#39;, 172),
 (&#39;back&#39;, 163),
 (&quot;it&#39;&quot;, 162),
 (&#39;know&#39;, 155),
 (&#39;new&#39;, 153)]
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [24]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">neg_count</span><span class="o">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>Out[24]:
</pre></div>
</div>
<div class="output_area highlight-none"><div class="highlight"><pre>
<span></span>[(&#39;:(&#39;, 4585),
 (&#39;:-(&#39;, 501),
 (&quot;i&#39;m&quot;, 343),
 (&#39;...&#39;, 332),
 (&#39;miss&#39;, 301),
 (&#39;pleas&#39;, 275),
 (&#39;follow&#39;, 263),
 (&#39;want&#39;, 246),
 (&#39;get&#39;, 233),
 (&#39;like&#39;, 223),
 (&#39;go&#39;, 218),
 (&#39;♛&#39;, 210),
 (&#39;》&#39;, 210),
 (&quot;can&#39;t&quot;, 180),
 (&quot;it&#39;&quot;, 178),
 (&quot;don&#39;t&quot;, 176),
 (&#39;time&#39;, 166),
 (&#39;u&#39;, 164),
 (&#39;feel&#39;, 158),
 (&#39;love&#39;, 151)]
</pre></div>
</div>
</div>
</div>
<div class="section" id="Runtime-and-optimizations">
<h3>Runtime and optimizations<a class="headerlink" href="#Runtime-and-optimizations" title="Permalink to this headline">¶</a></h3>
<p>How does the runtime change as we add all of these complications?</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [25]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">small_twt</span> <span class="o">=</span>  <span class="n">pos_tweets</span><span class="p">[:</span><span class="mi">2000</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [26]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="o">%%</span><span class="k">time</span>
# Base NLTK tokenizer
_ = tokenize_tweets1(small_twt)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
CPU times: user 344 ms, sys: 0 ns, total: 344 ms
Wall time: 340 ms
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [27]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="o">%%</span><span class="k">time</span>
# Twitter optimized tokenizer
_ = tokenize_tweets2(small_twt)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
CPU times: user 78.1 ms, sys: 15.6 ms, total: 93.8 ms
Wall time: 84.8 ms
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [28]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="o">%%</span><span class="k">time</span>
# Get rid of stop words and lowercase
_ = tokenize_tweets3(small_twt)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
CPU times: user 141 ms, sys: 0 ns, total: 141 ms
Wall time: 131 ms
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [29]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="o">%%</span><span class="k">time</span>
# Also stemming
_ = tokenize_tweets4(small_twt)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
CPU times: user 344 ms, sys: 15.6 ms, total: 359 ms
Wall time: 352 ms
</pre></div></div>
</div>
<p>Takeaways: - The general NLTK word tokenizer works on many problems, but
that generality makes it slow - Using a tokenizer optimized to your
problem will be faster - Adding more and more complications adds more
and more time - Sometimes need to work to optimize these also</p>
<p>This optimization really does matter. Here&#8217;s a &#8220;fast&#8221; version of
tokenization made for a specific project.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [30]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">re</span>

<span class="k">def</span> <span class="nf">word_tokenize</span><span class="p">(</span><span class="n">words</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Faster word tokenization than nltk.word_tokenize</span>
<span class="sd">    Input:</span>
<span class="sd">        words: a string to be tokenized</span>
<span class="sd">    Output:</span>
<span class="sd">        tokens: tokenized words</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;[a-z]+-?[a-z]+&quot;</span><span class="p">,</span> <span class="n">words</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>
    <span class="k">return</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [31]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">small_twt</span> <span class="o">=</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pos_tweets</span><span class="p">[:</span><span class="mi">10000</span><span class="p">])</span>
<span class="n">twt</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">tokenize</span><span class="o">.</span><span class="n">TweetTokenizer</span><span class="p">(</span><span class="n">strip_handles</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduce_len</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [32]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="o">%%</span><span class="k">time</span>
_ = nltk.word_tokenize(small_twt)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
CPU times: user 500 ms, sys: 15.6 ms, total: 516 ms
Wall time: 507 ms
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [33]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="o">%%</span><span class="k">time</span>
_ = twt.tokenize(small_twt)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
CPU times: user 188 ms, sys: 15.6 ms, total: 203 ms
Wall time: 194 ms
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [34]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="o">%%</span><span class="k">time</span>
_ = word_tokenize(small_twt)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
CPU times: user 31.2 ms, sys: 0 ns, total: 31.2 ms
Wall time: 26.6 ms
</pre></div></div>
</div>
<p>We can see that optimizing our tokenization can really help the speed.
But this tokenizer isn&#8217;t optimized for this problem. For instance, it
doesn&#8217;t pick up emoticons.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [35]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">Counter</span><span class="p">(</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">small_twt</span><span class="p">))</span><span class="o">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>Out[35]:
</pre></div>
</div>
<div class="output_area highlight-none"><div class="highlight"><pre>
<span></span>[(&#39;you&#39;, 1591),
 (&#39;co&#39;, 1196),
 (&#39;the&#39;, 1096),
 (&#39;to&#39;, 1094),
 (&#39;http&#39;, 856),
 (&#39;for&#39;, 772),
 (&#39;and&#39;, 706),
 (&#39;it&#39;, 681),
 (&#39;my&#39;, 560),
 (&#39;in&#39;, 505),
 (&#39;have&#39;, 436),
 (&#39;is&#39;, 434),
 (&#39;of&#39;, 413),
 (&#39;thanks&#39;, 393),
 (&#39;me&#39;, 364),
 (&#39;that&#39;, 343),
 (&#39;https&#39;, 336),
 (&#39;your&#39;, 333),
 (&#39;on&#39;, 326),
 (&#39;follow&#39;, 308)]
</pre></div>
</div>
</div>
<p>So we see that NLTK has some pros and cons: - Pros - Easy to use - Fast
enough for a one off analysis on small(ish) data - Great when (time to
code solution) &gt; (time to run NLTK) - Cons - Much slower than optimized
solutions - Really feel the crunch on larger corpora or large analyses</p>
</div>
<div class="section" id="More-involved-processing">
<h3>More involved processing<a class="headerlink" href="#More-involved-processing" title="Permalink to this headline">¶</a></h3>
<p>NLTK has many other modules to perform more complicated text
processsing.</p>
<p>We can get the parts of speech for each word in a sentence</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>In [36]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">tokens</span> <span class="o">=</span> <span class="n">word_tokenize</span><span class="p">(</span><span class="n">small_twt</span><span class="p">[:</span><span class="mi">100</span><span class="p">])</span>
<span class="n">nltk</span><span class="o">.</span><span class="n">pos_tag</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre>
<span></span>Out[36]:
</pre></div>
</div>
<div class="output_area highlight-none"><div class="highlight"><pre>
<span></span>[(&#39;followfriday&#39;, &#39;JJ&#39;),
 (&#39;france&#39;, &#39;NN&#39;),
 (&#39;inte&#39;, &#39;NN&#39;),
 (&#39;pkuchly&#39;, &#39;RB&#39;),
 (&#39;milipol&#39;, &#39;JJ&#39;),
 (&#39;paris&#39;, &#39;NN&#39;),
 (&#39;for&#39;, &#39;IN&#39;),
 (&#39;being&#39;, &#39;VBG&#39;),
 (&#39;top&#39;, &#39;JJ&#39;),
 (&#39;engaged&#39;, &#39;VBN&#39;),
 (&#39;members&#39;, &#39;NNS&#39;),
 (&#39;in&#39;, &#39;IN&#39;),
 (&#39;my&#39;, &#39;PRP$&#39;),
 (&#39;community&#39;, &#39;NN&#39;)]
</pre></div>
</div>
</div>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../index.html">Stat 159/259 - Reproducible and Collaborative Data Science</a></h1>








<h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../01-git/Git-Tutorial.html">An interactive Git Tutorial: the tool you didn&#8217;t know you needed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02-ipython/Index.html">A quick overview of the Jupyter Notebook and IPython</a></li>
<li class="toctree-l1"><a class="reference internal" href="../03-reading1-discussion.html">Reading discussion - Developing open source scientific practice</a></li>
<li class="toctree-l1"><a class="reference internal" href="../04-reading2-discussion.html">Reading discussion - Scientific Python, IPython, Jupyter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../05-class-practice.html">Class practice: strings, lists &amp; numbers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../06-conda-pip-environments.html">Conda and pip - managing environments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../07-reading3-discussion.html">From September 25 reading</a></li>
<li class="toctree-l1"><a class="reference internal" href="../07-reading3-discussion.html#Make:-automating-tasks">Make: automating tasks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../08-ligo-make.html">LIGO, the 2017 Nobel prize in physics, and wrapping up Makefiles</a></li>
<li class="toctree-l1"><a class="reference internal" href="../09-intro-numpy/intro-numpy.html">An Introduction to the Scientific Python Ecosystem</a></li>
<li class="toctree-l1"><a class="reference internal" href="../09-intro-numpy/intro-numpy.html#Motivation:-the-trapezoidal-rule">Motivation: the trapezoidal rule</a></li>
<li class="toctree-l1"><a class="reference internal" href="../09-intro-numpy/intro-numpy.html#NumPy-arrays:-the-right-data-structure-for-scientific-computing">NumPy arrays: the right data structure for scientific computing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../09-intro-numpy/intro-numpy.html#High-quality-data-visualization-with-Matplotlib">High quality data visualization with Matplotlib</a></li>
<li class="toctree-l1"><a class="reference internal" href="../09-intro-numpy/trapezoid.html">The trapezoidal rule: vectorization and perormance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../10-matplotlib_beyond_basics/10-matplotlib_beyond_basics.html">Matplotlib: Beyond the basics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../10-matplotlib_beyond_basics/10-matplotlib_live_plots.html">Matplotlib: Live plots</a></li>
<li class="toctree-l1"><a class="reference internal" href="../10-matplotlib_beyond_basics/image_tutorial.html">Matplotlib image tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../10-matplotlib_beyond_basics/image_tutorial.html#Multichannel-images">Multichannel images</a></li>
<li class="toctree-l1"><a class="reference internal" href="11-strings.html">Strings</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">NLTK: Natural Language Made Easy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../12-data-intro.html">Data - an introduction to the world of Pandas</a></li>
<li class="toctree-l1"><a class="reference internal" href="../13-data-frames.html">Data Manipulation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../14-sphinx.html">An introduction to Sphinx</a></li>
<li class="toctree-l1"><a class="reference internal" href="../15-pvalues/index.html">P-values discussion with Prof. Philip B. Stark</a></li>
<li class="toctree-l1"><a class="reference internal" href="../16-testing.html">Testing your software in Python</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../labs/lab1.html">Lab 1</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../labs/lab10.html">Lab 10</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../labs/lab2.html">Lab 2</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../labs/lab3.html">Lab 3</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../labs/lab4.html">Lab 4</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../labs/lab5.html">Lab 5</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../labs/lab6.html">Lab 6</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../labs/lab7.html">Lab 7</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../labs/lab8.html">Lab 8</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../labs/lab9.html">Lab 9</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../resources.html">Course resources</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../index.html">Documentation overview</a><ul>
      <li>Previous: <a href="11-strings.html" title="previous chapter">Strings</a></li>
      <li>Next: <a href="../12-data-intro.html" title="next chapter">Data - an introduction to the world of Pandas</a></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="../../search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2017, Fernando Perez.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.5.6</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.10</a>
      
      |
      <a href="../../_sources/lectures/11-strings/11-nltk.ipynb.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>